{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fgsm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3_S3BYtkupU"
      },
      "source": [
        "Reference# Adversarial Attacks with FGSM by PyImageSearch\n",
        "https://www.pyimagesearch.com/2021/03/01/adversarial-attacks-with-fgsm-fast-gradient-sign-method/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGWQ10dL5Jk6"
      },
      "source": [
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "#import tensorflow.python.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.losses import MSE\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjFMd5PD5sNq"
      },
      "source": [
        "\n",
        "def mse(pred, target):\n",
        "  return tf.square(pred-target)/2\n",
        "\n",
        "def generate_image_adversary(model, image, label, eps=2 / 255.0):\n",
        "    # cast the image\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    # record our gradients\n",
        "    print('value of epsilon: ', eps)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image) # explicitly indicate that our image should be tacked for gradient updates\n",
        "        pred = model(image) ## use our model to make predictions on the input image and\n",
        "        #print('shape of pred:', pred.shape, 'shape of label:', label.shape)\n",
        "        #print('pred: ', pred)\n",
        "        loss = MSE(label, pred) # compute the loss\n",
        "        print('loss', loss)\n",
        "\n",
        "    # calculate the gradients of loss with respect to the image, then\n",
        "    # and compute the sign of the gradient\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    signedGrad = tf.sign(gradient)\n",
        "    #print('sign', signedGrad)\n",
        "    # construct the image adversary\n",
        "    adversary = (image + (signedGrad * eps)).numpy()\n",
        "\n",
        "    # return the image adversary to the calling function\n",
        "    return adversary"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl8eql1k6RZt",
        "outputId": "b5cf2f0d-7054-46e0-9873-625163a56463"
      },
      "source": [
        "########### CONFIG ######################\n",
        "# Load and Normalize data.\n",
        "currentNetworkName = 'original_model_5250_5250'\n",
        "datasetName = 'ad1_43_UR_0_5250_5250'\n",
        "dataDir = 'assets/'\n",
        "dataFileName = dataDir + datasetName + '.sample'\n",
        "meta_data = 0\n",
        "cols = 22 + (meta_data * 2) # <2 uid rid> <8 user-attribs> <2 user_meta> <8 res-attribs> <2 res-meta> <4 ops>\n",
        "########### CONFIG END ###################\n",
        "\n",
        "# load the dataset\n",
        "raw_dataset = loadtxt(dataFileName, delimiter=' ', dtype=np.str)\n",
        "dataset = raw_dataset[:,2:cols] # TO SKIP UID RID\n",
        "#np.random.shuffle(dataset)\n",
        "\n",
        "# split into user-resource pair and operations variables\n",
        "feature = dataset.shape[1]\n",
        "print('Features:', feature)\n",
        "attribs = feature - 4\n",
        "\n",
        "urp = dataset[:,0:attribs]\n",
        "operations = dataset[:,attribs:feature]\n",
        "\n",
        "uattrib_end = 8\n",
        "rattrib_end = 16\n",
        "umeta_end = uattrib_end + meta_data\n",
        "rmeta_end = rattrib_end + meta_data\n",
        "\n",
        "urp = np.delete(urp, slice(uattrib_end, umeta_end), 1)\n",
        "print(urp.shape)\n",
        "urp = np.delete(urp, slice(rattrib_end, rmeta_end), 1)\n",
        "print(urp.shape)\n",
        "feature = urp.shape[1]\n",
        "print('Features after meta data removal:', feature)\n",
        "print(urp[0])\n",
        "print(operations[0])\n",
        "#split into training and test data\n",
        "eval_size = (int)(urp.shape[0] * 0.8) #20% of total dataset\n",
        "\n",
        "print('evaluation data size: ' + str(eval_size)) \n",
        "\n",
        "############### ENCODING ##############\n",
        "urp = to_categorical(urp)\n",
        "print('shape of URP after encoding')\n",
        "print(urp.shape)\n",
        "#######################################\n",
        "\n",
        "# test data\n",
        "urp_test = urp[:eval_size,0:feature]\n",
        "operations_test = operations[:eval_size,0:4]\n",
        "print('urp_test shape:', urp_test.shape)\n",
        "\n",
        "# trainin data\n",
        "urp_train = urp[eval_size:,0:feature]\n",
        "operations_train = operations[eval_size:,0:4]\n",
        "print('urp_train shape:', urp_train.shape)\n",
        "\n",
        "#determine batch size\n",
        "batch_size = min(urp_train.shape[0]/10, 16)\n",
        "print('batch size: ' + str(batch_size))\n",
        "\n",
        "x_train = urp_train[..., np.newaxis]\n",
        "x_test = urp_test[..., np.newaxis]\n",
        "print('shape of URT-Train after adding new dimension')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "y_train = operations_train\n",
        "y_test = operations_test\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Run training, without data augmentation.\n",
        "\n",
        "DIR_ASSETS = 'assets/'\n",
        "PATH_MODEL = DIR_ASSETS + currentNetworkName + '.hdf5'\n",
        "\n",
        "if os.path.exists(PATH_MODEL):\n",
        "    print('Loading trained model from {}.'.format(PATH_MODEL))\n",
        "    current_nw = load_model(PATH_MODEL)\n",
        "else:\n",
        "    print('No trained model found at {}.'.format(PATH_MODEL))\n",
        "    exit(0)\n",
        "\n",
        "print ('****************** ======== ******************')\n",
        "y_test_current_nw = current_nw.predict(x_test)\n",
        "y_test_current_nw = (y_test_current_nw > 0.5).astype(int)\n",
        "\n",
        "#print('successful!')\n",
        "\n",
        "# grab a sample and its label\n",
        "image = x_test[0]\n",
        "label = y_test[0].astype(float)\n",
        "\n",
        "# generate a sample adversary for the current sample and \n",
        "# make the prediction on the adversary\n",
        "print('Shape of image: ', image.shape)\n",
        "actual_pred = current_nw.predict(image.reshape(1, 16, 138, 1))\n",
        "actual_pred = (actual_pred > 0.5).astype(int)\n",
        "print('Actual Prediction', actual_pred)\n",
        "\n",
        "adversary = generate_image_adversary(current_nw, image.reshape(1, 16, 138, 1), label, eps=0.2)\n",
        "#print('adversarial image')\n",
        "#print(adversary.reshape(16, 138))\n",
        "advers_pred = current_nw.predict(adversary)\n",
        "advers_pred = (advers_pred > 0.5).astype(int)\n",
        "print('predict adversarial image', advers_pred)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: 20\n",
            "(43, 16)\n",
            "(43, 16)\n",
            "Features after meta data removal: 16\n",
            "['9' '23' '58' '45' '44' '48' '6' '18' '9' '82' '13' '46' '44' '38' '6'\n",
            " '45']\n",
            "['1' '0' '1' '0']\n",
            "evaluation data size: 34\n",
            "shape of URP after encoding\n",
            "(43, 16, 138)\n",
            "urp_test shape: (34, 16, 138)\n",
            "urp_train shape: (9, 16, 138)\n",
            "batch size: 0.9\n",
            "shape of URT-Train after adding new dimension\n",
            "x_train shape: (9, 16, 138, 1)\n",
            "x_test shape: (34, 16, 138, 1)\n",
            "9 train samples\n",
            "34 test samples\n",
            "y_train shape: (9, 4)\n",
            "Loading trained model from assets/original_model_5250_5250.hdf5.\n",
            "****************** ======== ******************\n",
            "Shape of image:  (16, 138, 1)\n",
            "Actual Prediction [[1 0 0 0]]\n",
            "value of epsilon:  0.2\n",
            "loss tf.Tensor([[1.5511192e-08 2.4499921e-06 4.9993467e-01 6.0245549e-07]], shape=(1, 4), dtype=float32)\n",
            "predict adversarial image [[1 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtYE-J7RKXPw"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "'''\n",
        "img_adv = adversary.reshape(16, 138)\n",
        "img = image.reshape(16, 138)\n",
        "print(img.shape)\n",
        "non_zero_count = 0\n",
        "for i in range(img.shape[0]):\n",
        "  for j in range(img.shape[1]):\n",
        "    if(img[i][j] != 0):\n",
        "      non_zero_count = non_zero_count + 1\n",
        "      print(img_adv[i][j]) # to see the pixel's value change in adversarial image \n",
        "print('total non zero pixels', non_zero_count)\n",
        "'''\n",
        "\n",
        "'''\n",
        "\n",
        "print(img_adv.shape)\n",
        "non_zero_count = 0\n",
        "for i in range(img_adv.shape[0]):\n",
        "  for j in range(img_adv.shape[1]):\n",
        "    if(img_adv[i][j] != 0):\n",
        "      non_zero_count = non_zero_count + 1\n",
        "print('total non zero pixels', non_zero_count)\n",
        "'''\n",
        "output = Image.fromarray(image.reshape(16, 138), 'RGB')\n",
        "output.save('input_image.png')\n",
        "\n",
        "output = Image.fromarray(adversary.reshape(16, 138), 'RGB')\n",
        "output.save('adversary_image.png')\n"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}